{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Frames:\n",
      "Video: bxfwiuvafo.mp4, Frames: ['273', '286', '298']\n",
      "Video: hipzzheqlg.mp4, Frames: ['133', '141', '148', '154']\n",
      "Video: mibbivalty.mp4, Frames: ['45', '50', '55', '72', '78', '99', '110', '118', '131', '143', '156', '166', '182', '225', '235', '246', '277', '289', '300']\n",
      "Video: azseubmxrc.mp4, Frames: ['57', '63', '70', '78', '86', '93', '109', '118', '147']\n",
      "Video: brvsnraikz.mp4, Frames: ['110', '115', '121', '131', '143', '189', '259']\n",
      "Video: bzqkplrsnt.mp4, Frames: ['151', '164', '175', '189']\n",
      "Video: fkkmxwjkxb.mp4, Frames: ['34', '41', '49', '54', '62', '73', '84', '137', '146', '154', '162']\n",
      "Video: ekmwbuaedp.mp4, Frames: ['27', '32', '39', '45', '54', '61', '73', '81', '89', '97', '105', '112', '124', '132']\n",
      "Video: airktntzqp.mp4, Frames: ['200', '213', '228', '236', '248']\n",
      "Video: jgijuusdev.mp4, Frames: ['53', '59', '66', '74', '87', '97', '104', '112', '123', '130', '142']\n",
      "\n",
      "Test Frames:\n",
      "Video: dsnerafcqv.mp4, Frames: ['61', '75', '88', '98', '111', '119']\n",
      "Video: gwnaxtndii.mp4, Frames: ['288', '294', '300']\n",
      "Video: gcbyurxhbz.mp4, Frames: ['140', '144', '149', '155', '179', '189']\n",
      "Video: huhxwuihzm.mp4, Frames: ['60', '65', '72', '84']\n",
      "Video: cybfrdydog.mp4, Frames: ['29', '36', '41', '48', '54', '60', '65']\n",
      "Video: dcyizhgzmd.mp4, Frames: ['157', '162', '169', '176', '199', '204', '210']\n",
      "Video: factpeezlu.mp4, Frames: ['278', '288', '300']\n",
      "Video: jmoqelikic.mp4, Frames: ['51', '56', '62', '68', '76']\n",
      "Video: bfeycvkedq.mp4, Frames: ['132', '144', '155', '163', '179']\n",
      "Video: kjhcwydrmb.mp4, Frames: ['107', '122', '140', '152']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('H:\\\\xai-unibuc\\\\xAI_deepfake\\\\my_database3.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define a function to get the relevant frames from the 'click_locations' column\n",
    "def get_relevant_frames(limit=20):\n",
    "    cursor.execute(\"SELECT video_name, click_locations FROM annotations LIMIT ?\", (limit,))\n",
    "    data = cursor.fetchall()\n",
    "    \n",
    "    train_frames = {}\n",
    "    test_frames = {}\n",
    "    \n",
    "    # Split the data into train and test (first 10 for train, next 10 for test)\n",
    "    for idx, (video_name, click_locations) in enumerate(data):\n",
    "        frame_data = json.loads(click_locations)\n",
    "        relevant_frames = list(frame_data.keys())\n",
    "        \n",
    "        if idx < 10:\n",
    "            train_frames[video_name] = relevant_frames\n",
    "        else:\n",
    "            test_frames[video_name] = relevant_frames\n",
    "    \n",
    "    return train_frames, test_frames\n",
    "\n",
    "# Extract train and test frames\n",
    "train_frames, test_frames = get_relevant_frames()\n",
    "\n",
    "# Display the extracted frames\n",
    "print(\"Train Frames:\")\n",
    "for video, frames in train_frames.items():\n",
    "    print(f\"Video: {video}, Frames: {frames}\")\n",
    "\n",
    "print(\"\\nTest Frames:\")\n",
    "for video, frames in test_frames.items():\n",
    "    print(f\"Video: {video}, Frames: {frames}\")\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database at h:\\xai-unibuc\\xAI_deepfake\\my_database3.db\n",
      "Fetching relevant frames from the database...\n",
      "Train frames: {'bxfwiuvafo.mp4': ['273', '286', '298'], 'hipzzheqlg.mp4': ['133', '141', '148', '154'], 'mibbivalty.mp4': ['45', '50', '55', '72', '78', '99', '110', '118', '131', '143', '156', '166', '182', '225', '235', '246', '277', '289', '300'], 'azseubmxrc.mp4': ['57', '63', '70', '78', '86', '93', '109', '118', '147'], 'brvsnraikz.mp4': ['110', '115', '121', '131', '143', '189', '259'], 'bzqkplrsnt.mp4': ['151', '164', '175', '189'], 'fkkmxwjkxb.mp4': ['34', '41', '49', '54', '62', '73', '84', '137', '146', '154', '162'], 'ekmwbuaedp.mp4': ['27', '32', '39', '45', '54', '61', '73', '81', '89', '97', '105', '112', '124', '132'], 'airktntzqp.mp4': ['200', '213', '228', '236', '248'], 'jgijuusdev.mp4': ['53', '59', '66', '74', '87', '97', '104', '112', '123', '130', '142']}\n",
      "Test frames: {'dsnerafcqv.mp4': ['61', '75', '88', '98', '111', '119'], 'gwnaxtndii.mp4': ['288', '294', '300'], 'gcbyurxhbz.mp4': ['140', '144', '149', '155', '179', '189'], 'huhxwuihzm.mp4': ['60', '65', '72', '84'], 'cybfrdydog.mp4': ['29', '36', '41', '48', '54', '60', '65'], 'dcyizhgzmd.mp4': ['157', '162', '169', '176', '199', '204', '210'], 'factpeezlu.mp4': ['278', '288', '300'], 'jmoqelikic.mp4': ['51', '56', '62', '68', '76'], 'bfeycvkedq.mp4': ['132', '144', '155', '163', '179'], 'kjhcwydrmb.mp4': ['107', '122', '140', '152']}\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bxfwiuvafo.mp4\n",
      "Extracting frame 273 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bxfwiuvafo.mp4\n",
      "Frame 273 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bxfwiuvafo.mp4\n",
      "Encoded frame 273 for video bxfwiuvafo.mp4\n",
      "Extracting frame 286 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bxfwiuvafo.mp4\n",
      "Frame 286 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bxfwiuvafo.mp4\n",
      "Encoded frame 286 for video bxfwiuvafo.mp4\n",
      "Extracting frame 298 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bxfwiuvafo.mp4\n",
      "Frame 298 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bxfwiuvafo.mp4\n",
      "Encoded frame 298 for video bxfwiuvafo.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Extracting frame 133 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Frame 133 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Encoded frame 133 for video hipzzheqlg.mp4\n",
      "Extracting frame 141 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Frame 141 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Encoded frame 141 for video hipzzheqlg.mp4\n",
      "Extracting frame 148 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Frame 148 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Encoded frame 148 for video hipzzheqlg.mp4\n",
      "Extracting frame 154 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Frame 154 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\hipzzheqlg.mp4\n",
      "Encoded frame 154 for video hipzzheqlg.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Extracting frame 45 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 45 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 45 for video mibbivalty.mp4\n",
      "Extracting frame 50 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 50 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 50 for video mibbivalty.mp4\n",
      "Extracting frame 55 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 55 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 55 for video mibbivalty.mp4\n",
      "Extracting frame 72 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 72 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 72 for video mibbivalty.mp4\n",
      "Extracting frame 78 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 78 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 78 for video mibbivalty.mp4\n",
      "Extracting frame 99 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 99 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 99 for video mibbivalty.mp4\n",
      "Extracting frame 110 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 110 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 110 for video mibbivalty.mp4\n",
      "Extracting frame 118 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 118 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 118 for video mibbivalty.mp4\n",
      "Extracting frame 131 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 131 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 131 for video mibbivalty.mp4\n",
      "Extracting frame 143 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 143 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 143 for video mibbivalty.mp4\n",
      "Extracting frame 156 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 156 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 156 for video mibbivalty.mp4\n",
      "Extracting frame 166 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 166 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 166 for video mibbivalty.mp4\n",
      "Extracting frame 182 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 182 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 182 for video mibbivalty.mp4\n",
      "Extracting frame 225 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 225 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 225 for video mibbivalty.mp4\n",
      "Extracting frame 235 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 235 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 235 for video mibbivalty.mp4\n",
      "Extracting frame 246 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 246 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 246 for video mibbivalty.mp4\n",
      "Extracting frame 277 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 277 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 277 for video mibbivalty.mp4\n",
      "Extracting frame 289 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Frame 289 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Encoded frame 289 for video mibbivalty.mp4\n",
      "Extracting frame 300 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Failed to read frame 300 from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\mibbivalty.mp4\n",
      "Skipped frame 300 for video mibbivalty.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Extracting frame 57 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 57 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 57 for video azseubmxrc.mp4\n",
      "Extracting frame 63 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 63 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 63 for video azseubmxrc.mp4\n",
      "Extracting frame 70 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 70 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 70 for video azseubmxrc.mp4\n",
      "Extracting frame 78 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 78 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 78 for video azseubmxrc.mp4\n",
      "Extracting frame 86 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 86 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 86 for video azseubmxrc.mp4\n",
      "Extracting frame 93 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 93 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 93 for video azseubmxrc.mp4\n",
      "Extracting frame 109 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 109 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 109 for video azseubmxrc.mp4\n",
      "Extracting frame 118 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 118 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 118 for video azseubmxrc.mp4\n",
      "Extracting frame 147 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Frame 147 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\azseubmxrc.mp4\n",
      "Encoded frame 147 for video azseubmxrc.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Extracting frame 110 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Frame 110 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Encoded frame 110 for video brvsnraikz.mp4\n",
      "Extracting frame 115 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Frame 115 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Encoded frame 115 for video brvsnraikz.mp4\n",
      "Extracting frame 121 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Frame 121 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Encoded frame 121 for video brvsnraikz.mp4\n",
      "Extracting frame 131 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Frame 131 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Encoded frame 131 for video brvsnraikz.mp4\n",
      "Extracting frame 143 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Frame 143 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Encoded frame 143 for video brvsnraikz.mp4\n",
      "Extracting frame 189 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Frame 189 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Encoded frame 189 for video brvsnraikz.mp4\n",
      "Extracting frame 259 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Frame 259 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\brvsnraikz.mp4\n",
      "Encoded frame 259 for video brvsnraikz.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Extracting frame 151 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Frame 151 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Encoded frame 151 for video bzqkplrsnt.mp4\n",
      "Extracting frame 164 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Frame 164 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Encoded frame 164 for video bzqkplrsnt.mp4\n",
      "Extracting frame 175 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Frame 175 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Encoded frame 175 for video bzqkplrsnt.mp4\n",
      "Extracting frame 189 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Frame 189 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bzqkplrsnt.mp4\n",
      "Encoded frame 189 for video bzqkplrsnt.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Extracting frame 34 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 34 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 34 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 41 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 41 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 41 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 49 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 49 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 49 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 54 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 54 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 54 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 62 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 62 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 62 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 73 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 73 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 73 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 84 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 84 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 84 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 137 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 137 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 137 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 146 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 146 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 146 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 154 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 154 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 154 for video fkkmxwjkxb.mp4\n",
      "Extracting frame 162 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Frame 162 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\fkkmxwjkxb.mp4\n",
      "Encoded frame 162 for video fkkmxwjkxb.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Extracting frame 27 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 27 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 27 for video ekmwbuaedp.mp4\n",
      "Extracting frame 32 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 32 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 32 for video ekmwbuaedp.mp4\n",
      "Extracting frame 39 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 39 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 39 for video ekmwbuaedp.mp4\n",
      "Extracting frame 45 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 45 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 45 for video ekmwbuaedp.mp4\n",
      "Extracting frame 54 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 54 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 54 for video ekmwbuaedp.mp4\n",
      "Extracting frame 61 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 61 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 61 for video ekmwbuaedp.mp4\n",
      "Extracting frame 73 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 73 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 73 for video ekmwbuaedp.mp4\n",
      "Extracting frame 81 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 81 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 81 for video ekmwbuaedp.mp4\n",
      "Extracting frame 89 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 89 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 89 for video ekmwbuaedp.mp4\n",
      "Extracting frame 97 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 97 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 97 for video ekmwbuaedp.mp4\n",
      "Extracting frame 105 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 105 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 105 for video ekmwbuaedp.mp4\n",
      "Extracting frame 112 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 112 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 112 for video ekmwbuaedp.mp4\n",
      "Extracting frame 124 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 124 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 124 for video ekmwbuaedp.mp4\n",
      "Extracting frame 132 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Frame 132 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\ekmwbuaedp.mp4\n",
      "Encoded frame 132 for video ekmwbuaedp.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Extracting frame 200 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Frame 200 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Encoded frame 200 for video airktntzqp.mp4\n",
      "Extracting frame 213 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Frame 213 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Encoded frame 213 for video airktntzqp.mp4\n",
      "Extracting frame 228 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Frame 228 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Encoded frame 228 for video airktntzqp.mp4\n",
      "Extracting frame 236 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Frame 236 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Encoded frame 236 for video airktntzqp.mp4\n",
      "Extracting frame 248 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Frame 248 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\airktntzqp.mp4\n",
      "Encoded frame 248 for video airktntzqp.mp4\n",
      "Processing video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Extracting frame 53 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 53 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 53 for video jgijuusdev.mp4\n",
      "Extracting frame 59 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 59 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 59 for video jgijuusdev.mp4\n",
      "Extracting frame 66 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 66 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 66 for video jgijuusdev.mp4\n",
      "Extracting frame 74 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 74 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 74 for video jgijuusdev.mp4\n",
      "Extracting frame 87 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 87 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 87 for video jgijuusdev.mp4\n",
      "Extracting frame 97 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 97 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 97 for video jgijuusdev.mp4\n",
      "Extracting frame 104 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 104 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 104 for video jgijuusdev.mp4\n",
      "Extracting frame 112 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 112 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 112 for video jgijuusdev.mp4\n",
      "Extracting frame 123 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 123 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 123 for video jgijuusdev.mp4\n",
      "Extracting frame 130 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 130 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 130 for video jgijuusdev.mp4\n",
      "Extracting frame 142 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Frame 142 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jgijuusdev.mp4\n",
      "Encoded frame 142 for video jgijuusdev.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Extracting frame 61 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Frame 61 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Extracting frame 75 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Frame 75 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Extracting frame 88 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Frame 88 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Extracting frame 98 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Frame 98 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Extracting frame 111 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Frame 111 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Extracting frame 119 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Frame 119 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dsnerafcqv.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gwnaxtndii.mp4\n",
      "Extracting frame 288 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gwnaxtndii.mp4\n",
      "Frame 288 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gwnaxtndii.mp4\n",
      "Extracting frame 294 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gwnaxtndii.mp4\n",
      "Frame 294 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gwnaxtndii.mp4\n",
      "Extracting frame 300 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gwnaxtndii.mp4\n",
      "Failed to read frame 300 from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gwnaxtndii.mp4\n",
      "Skipped test frame 300 for video gwnaxtndii.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Extracting frame 140 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Frame 140 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Extracting frame 144 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Frame 144 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Extracting frame 149 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Frame 149 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Extracting frame 155 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Frame 155 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Extracting frame 179 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Frame 179 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Extracting frame 189 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Frame 189 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\gcbyurxhbz.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Extracting frame 60 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Frame 60 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Extracting frame 65 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Frame 65 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Extracting frame 72 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Frame 72 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Extracting frame 84 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Frame 84 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\huhxwuihzm.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Extracting frame 29 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Frame 29 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Extracting frame 36 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Frame 36 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Extracting frame 41 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Frame 41 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Extracting frame 48 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Frame 48 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Extracting frame 54 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Frame 54 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Extracting frame 60 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Frame 60 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Extracting frame 65 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Frame 65 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\cybfrdydog.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Extracting frame 157 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Frame 157 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Extracting frame 162 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Frame 162 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Extracting frame 169 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Frame 169 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Extracting frame 176 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Frame 176 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Extracting frame 199 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Frame 199 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Extracting frame 204 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Frame 204 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Extracting frame 210 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Frame 210 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\dcyizhgzmd.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\factpeezlu.mp4\n",
      "Extracting frame 278 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\factpeezlu.mp4\n",
      "Frame 278 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\factpeezlu.mp4\n",
      "Extracting frame 288 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\factpeezlu.mp4\n",
      "Frame 288 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\factpeezlu.mp4\n",
      "Extracting frame 300 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\factpeezlu.mp4\n",
      "Failed to read frame 300 from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\factpeezlu.mp4\n",
      "Skipped test frame 300 for video factpeezlu.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Extracting frame 51 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Frame 51 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Extracting frame 56 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Frame 56 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Extracting frame 62 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Frame 62 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Extracting frame 68 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Frame 68 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Extracting frame 76 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Frame 76 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\jmoqelikic.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Extracting frame 132 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Frame 132 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Extracting frame 144 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Frame 144 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Extracting frame 155 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Frame 155 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Extracting frame 163 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Frame 163 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Extracting frame 179 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Frame 179 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\bfeycvkedq.mp4\n",
      "Processing test video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Extracting frame 107 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Frame 107 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Extracting frame 122 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Frame 122 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Extracting frame 140 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Frame 140 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Extracting frame 152 from video: h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Frame 152 successfully read from h:\\xai-unibuc\\xAI_deepfake\\deepfake_dataset_challenge\\dfdc_train_part_47\\kjhcwydrmb.mp4\n",
      "Most Similar Pair:\n",
      "Test Video: kjhcwydrmb.mp4 at frame 140\n",
      "Train Video: bzqkplrsnt.mp4 at frame 164\n",
      "Cosine Similarity (Highest): 0.9454\n",
      "\n",
      "Least Similar Pair:\n",
      "Test Video: dcyizhgzmd.mp4 at frame 199\n",
      "Train Video: azseubmxrc.mp4 at frame 109\n",
      "Cosine Similarity (Lowest): 0.0913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path.cwd()\n",
    "database_path = base_dir.parent / 'my_database3.db'\n",
    "video_dir = base_dir.parent / 'deepfake_dataset_challenge' / 'dfdc_train_part_47'\n",
    "\n",
    "if database_path.exists():\n",
    "    try:\n",
    "        conn = sqlite3.connect(str(database_path))\n",
    "        cursor = conn.cursor()\n",
    "        # Check if the 'annotations' table exists\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='annotations';\")\n",
    "        if not cursor.fetchone():\n",
    "            raise sqlite3.OperationalError(\"Table 'annotations' does not exist in the database.\")\n",
    "        print(f\"Connected to database at {database_path}\")\n",
    "    except sqlite3.Error as e:\n",
    "        raise sqlite3.Error(f\"An error occurred while connecting to the database: {e}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Database file not found at {database_path}\")\n",
    "\n",
    "# Load the ResNet model and preprocessing function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "try:\n",
    "    model = models.resnet50(pretrained=True).eval().to(device)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load the ResNet model: {e}\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Specify the layer identifier from which to extract features\n",
    "layer_identifier = 'last'  # Options: 'first', 'last', integer index\n",
    "\n",
    "# Collect all convolutional layers in the model\n",
    "conv_layers = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        conv_layers.append((name, module))\n",
    "\n",
    "def get_layer_by_identifier(identifier):\n",
    "    if identifier == 'first':\n",
    "        return conv_layers[0][1], conv_layers[0][0]  # module, name\n",
    "    elif identifier == 'last':\n",
    "        return conv_layers[-1][1], conv_layers[-1][0]\n",
    "    elif isinstance(identifier, int):\n",
    "        if 0 <= identifier < len(conv_layers):\n",
    "            return conv_layers[identifier][1], conv_layers[identifier][0]\n",
    "        else:\n",
    "            print(f\"Invalid layer index: {identifier}. Must be between 0 and {len(conv_layers)-1}.\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"Invalid layer identifier: {identifier}\")\n",
    "        return None, None\n",
    "\n",
    "# Define a function to get the relevant frames from 'click_locations' \n",
    "def get_relevant_frames(limit=20):\n",
    "    print(\"Fetching relevant frames from the database...\")\n",
    "    try:\n",
    "        cursor.execute(\"SELECT video_name, click_locations FROM annotations LIMIT ?\", (limit,))\n",
    "        data = cursor.fetchall()\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred while fetching data from the database: {e}\")\n",
    "        return {}, {}\n",
    "    if not data:\n",
    "        print(\"No data fetched from the database.\")\n",
    "        return {}, {}\n",
    "\n",
    "    train_frames = {}\n",
    "    test_frames = {}\n",
    "\n",
    "    # Split the data into train and test (first 10 for train, next 10 for test)\n",
    "    for idx, (video_name, click_locations) in enumerate(data):\n",
    "        try:\n",
    "            frame_data = json.loads(click_locations)\n",
    "            if not isinstance(frame_data, dict):\n",
    "                print(f\"Invalid data format for video {video_name}. Expected a JSON object.\")\n",
    "                continue\n",
    "            relevant_frames = list(frame_data.keys())\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decoding error for video {video_name}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing video {video_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if idx < 10:\n",
    "            train_frames[video_name] = relevant_frames\n",
    "        else:\n",
    "            test_frames[video_name] = relevant_frames\n",
    "\n",
    "    if not train_frames:\n",
    "        print(\"No training frames found.\")\n",
    "    if not test_frames:\n",
    "        print(\"No testing frames found.\")\n",
    "\n",
    "    print(f\"Train frames: {train_frames}\")\n",
    "    print(f\"Test frames: {test_frames}\")\n",
    "    return train_frames, test_frames\n",
    "\n",
    "# Function to extract frames from video using frame indices and encode them using ResNet\n",
    "def extract_and_encode_frame(video_path, frame_number, layer_identifier):\n",
    "    print(f\"Extracting frame {frame_number} from video: {video_path}\")\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video file: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        frame_number = int(frame_number)\n",
    "    except ValueError:\n",
    "        print(f\"Invalid frame number: {frame_number}\")\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        print(f\"Frame {frame_number} successfully read from {video_path}\")\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        image = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "        intermediate_output = []\n",
    "\n",
    "        def hook_fn(module, input, output):\n",
    "            intermediate_output.append(output)\n",
    "\n",
    "        # Get the convolutional layer module based on the idx\n",
    "        layer, layer_name = get_layer_by_identifier(layer_identifier)\n",
    "        if layer is None:\n",
    "            cap.release()\n",
    "            return None\n",
    "\n",
    "        # Register the hook\n",
    "        handle = layer.register_forward_hook(hook_fn)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _ = model(image)\n",
    "\n",
    "        # Remove the hook\n",
    "        handle.remove()\n",
    "        cap.release()\n",
    "\n",
    "        # Get the output features\n",
    "        if intermediate_output:\n",
    "            image_features = intermediate_output[0]\n",
    "            # Flatten the features and normalize\n",
    "            image_features = image_features.view(image_features.size(0), -1)\n",
    "            norm = image_features.norm(dim=-1, keepdim=True)\n",
    "            if torch.any(norm == 0):\n",
    "                print(f\"Zero norm encountered in features for frame {frame_number} in video {video_path}\")\n",
    "                return None\n",
    "            image_features /= norm\n",
    "            return image_features\n",
    "        else:\n",
    "            print(f\"Failed to get features from layer '{layer_name}'\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to read frame {frame_number} from {video_path}\")\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "def display_frames(video_path1, frame_num1, video_path2, frame_num2, window_title):\n",
    "    cap1 = cv2.VideoCapture(str(video_path1))\n",
    "    cap2 = cv2.VideoCapture(str(video_path2))\n",
    "\n",
    "    if not cap1.isOpened():\n",
    "        print(f\"Failed to open video file: {video_path1}\")\n",
    "        return\n",
    "    if not cap2.isOpened():\n",
    "        print(f\"Failed to open video file: {video_path2}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        frame_num1 = int(frame_num1)\n",
    "        frame_num2 = int(frame_num2)\n",
    "    except ValueError:\n",
    "        print(f\"Invalid frame numbers: {frame_num1}, {frame_num2}\")\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        return\n",
    "\n",
    "    # Set the video to the specified frame for video 1\n",
    "    cap1.set(cv2.CAP_PROP_POS_FRAMES, frame_num1)\n",
    "    ret1, frame1 = cap1.read()\n",
    "    if not ret1:\n",
    "        print(f\"Failed to read frame {frame_num1} from {video_path1}\")\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        return\n",
    "\n",
    "    # Set the video to the specified frame for video 2\n",
    "    cap2.set(cv2.CAP_PROP_POS_FRAMES, frame_num2)\n",
    "    ret2, frame2 = cap2.read()\n",
    "    if not ret2:\n",
    "        print(f\"Failed to read frame {frame_num2} from {video_path2}\")\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        return\n",
    "\n",
    "    # resize frames for display\n",
    "    frame1 = cv2.resize(frame1, (640, 360))\n",
    "    frame2 = cv2.resize(frame2, (640, 360))\n",
    "    concatenated_frame = np.hstack((frame1, frame2))\n",
    "    cv2.imshow(window_title, concatenated_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "\n",
    "train_frames, test_frames = get_relevant_frames()\n",
    "train_embeddings = {}\n",
    "\n",
    "# Encode training frames\n",
    "for video, frames in train_frames.items():\n",
    "    video_path = video_dir / video\n",
    "    if video_path.exists():\n",
    "        print(f\"Processing video: {video_path}\")\n",
    "        for frame in frames:\n",
    "            try:\n",
    "                frame_number = int(frame)\n",
    "            except ValueError:\n",
    "                print(f\"Invalid frame number: {frame}\")\n",
    "                continue\n",
    "            embedding = extract_and_encode_frame(video_path, frame_number, layer_identifier)\n",
    "            if embedding is not None:\n",
    "                train_embeddings[(video, frame_number)] = embedding\n",
    "                print(f\"Encoded frame {frame_number} for video {video}\")\n",
    "            else:\n",
    "                print(f\"Skipped frame {frame_number} for video {video}\")\n",
    "    else:\n",
    "        print(f\"Video file not found: {video_path}\")\n",
    "\n",
    "highest_similarity = -1\n",
    "lowest_similarity = float('inf')\n",
    "highest_pair = None\n",
    "lowest_pair = None\n",
    "\n",
    "for test_video, test_frames_list in test_frames.items():\n",
    "    test_video_path = video_dir / test_video\n",
    "    if test_video_path.exists():\n",
    "        print(f\"Processing test video: {test_video_path}\")\n",
    "        for test_frame in test_frames_list:\n",
    "            try:\n",
    "                test_frame_number = int(test_frame)\n",
    "            except ValueError:\n",
    "                print(f\"Invalid test frame number: {test_frame}\")\n",
    "                continue\n",
    "            test_embedding = extract_and_encode_frame(test_video_path, test_frame_number, layer_identifier)\n",
    "            if test_embedding is not None:\n",
    "                for (train_video, train_frame), train_embedding in train_embeddings.items():\n",
    "                    test_embedding = test_embedding.to(device)\n",
    "                    train_embedding = train_embedding.to(device)\n",
    "                    if test_embedding.shape != train_embedding.shape:\n",
    "                        print(f\"Shape mismatch between test embedding and train embedding.\")\n",
    "                        continue\n",
    "                    try:\n",
    "                        similarity = cosine_similarity(test_embedding, train_embedding).item()\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error computing similarity: {e}\")\n",
    "                        continue\n",
    "                    if similarity > highest_similarity:\n",
    "                        highest_similarity = similarity\n",
    "                        highest_pair = ((test_video, test_frame_number), (train_video, train_frame))\n",
    "                    if similarity < lowest_similarity:\n",
    "                        lowest_similarity = similarity\n",
    "                        lowest_pair = ((test_video, test_frame_number), (train_video, train_frame))\n",
    "            else:\n",
    "                print(f\"Skipped test frame {test_frame_number} for video {test_video}\")\n",
    "    else:\n",
    "        print(f\"Test video file not found: {test_video_path}\")\n",
    "\n",
    "# Display the most and least similar frames at the end\n",
    "if highest_pair and lowest_pair:\n",
    "    print(f\"Most Similar Pair:\")\n",
    "    print(f\"Test Video: {highest_pair[0][0]} at frame {highest_pair[0][1]}\")\n",
    "    print(f\"Train Video: {highest_pair[1][0]} at frame {highest_pair[1][1]}\")\n",
    "    print(f\"Cosine Similarity (Highest): {highest_similarity:.4f}\\n\")\n",
    "\n",
    "    print(f\"Least Similar Pair:\")\n",
    "    print(f\"Test Video: {lowest_pair[0][0]} at frame {lowest_pair[0][1]}\")\n",
    "    print(f\"Train Video: {lowest_pair[1][0]} at frame {lowest_pair[1][1]}\")\n",
    "    print(f\"Cosine Similarity (Lowest): {lowest_similarity:.4f}\\n\")\n",
    "\n",
    "    test_video_path_high = video_dir / highest_pair[0][0]\n",
    "    train_video_path_high = video_dir / highest_pair[1][0]\n",
    "    test_video_path_low = video_dir / lowest_pair[0][0]\n",
    "    train_video_path_low = video_dir / lowest_pair[1][0]\n",
    "\n",
    "    # Display the most similar frames\n",
    "    display_frames(\n",
    "        test_video_path_high, highest_pair[0][1],\n",
    "        train_video_path_high, highest_pair[1][1],\n",
    "        'Most Similar Frames'\n",
    "    )\n",
    "\n",
    "    # Display the least similar frames\n",
    "    display_frames(\n",
    "        test_video_path_low, lowest_pair[0][1],\n",
    "        train_video_path_low, lowest_pair[1][1],\n",
    "        'Least Similar Frames'\n",
    "    )\n",
    "else:\n",
    "    print(\"Could not find most and least similar pairs.\")\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module transformers has no attribute Phi3VImageProcessor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-vision-128k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mAutoProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, torch_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     13\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<|user|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\edy45\\miniconda3\\envs\\mlops\\lib\\site-packages\\transformers\\models\\auto\\processing_auto.py:288\u001b[0m, in \u001b[0;36mAutoProcessor.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(pretrained_model_name_or_path):\n\u001b[0;32m    287\u001b[0m         processor_class\u001b[38;5;241m.\u001b[39mregister_for_auto_class()\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processor_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    289\u001b[0m         pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    290\u001b[0m     )\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processor_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    293\u001b[0m         pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    294\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\edy45\\miniconda3\\envs\\mlops\\lib\\site-packages\\transformers\\processing_utils.py:228\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[1;32m--> 228\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_arguments_from_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\edy45\\miniconda3\\envs\\mlops\\lib\\site-packages\\transformers\\processing_utils.py:270\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m             attribute_class \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(attribute_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[1;32mc:\\Users\\edy45\\miniconda3\\envs\\mlops\\lib\\site-packages\\transformers\\utils\\import_utils.py:1346\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[1;31mAttributeError\u001b[0m: module transformers has no attribute Phi3VImageProcessor"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoProcessor\n",
    "import numpy as np\n",
    "\n",
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, torch_dtype=\"auto\").cuda()\n",
    "\n",
    "user_prompt = '<|user|>\\n'\n",
    "assistant_prompt = '<|assistant|>\\n'\n",
    "prompt_suffix = \"<|end|>\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -U\n",
    "!pip install datasets -U\n",
    "!pip install torch -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flash-attn --no-build-isolation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
